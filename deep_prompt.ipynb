{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c205834e-3cee-4428-9101-c89cc4c673ba",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffa0d176-e24b-43c1-91ee-c5214e1278d6",
   "metadata": {},
   "source": [
    "%pip install -U kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d49818-5611-485e-bd7b-e27cf92dac39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (2.7.0+cpu)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (2.3.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (4.52.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (2.2.6)\n",
      "Requirement already satisfied: requests in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (3.10.6)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.32.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->bert-score) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->bert-score) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->bert-score) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\songa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bert-score sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c875e9c-12ab-47b6-b7c3-a26f5e1aace3",
   "metadata": {},
   "source": [
    "## í‰ê°€ì§€í‘œ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f10e9aa-c317-4e23-ace2-f93524710f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: From C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "W1102 23:11:17.564000 2604 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # í•„ìš” ì‹œ ì‚¬ìš©\n",
    "import kss\n",
    "\n",
    "# datetime: ì¼ê´€ë˜ê²Œ from-import ì‚¬ìš©\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# NLP / embedding / LLM libs\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "API_KEY = \"your-api-key\"\n",
    "\n",
    "# ========================\n",
    "# FAISS ë²¡í„°DB ë¡œë“œ\n",
    "# ========================\n",
    "def load_vectorstore(api_key):\n",
    "    embedding_model = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"vectorDB/faiss_vectorDB\",\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    return retriever, vectorstore, embedding_model\n",
    "\n",
    "\n",
    "# ========================\n",
    "# ---- ìœ ì‚¬ë„ í‰ê°€ ìœ í‹¸ ----\n",
    "# ========================\n",
    "def _tokens(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^0-9a-zê°€-í£\\s]\", \" \", s)\n",
    "    return s.split()\n",
    "\n",
    "def prf1_unigram(hyp, ref):\n",
    "    ht, rt = Counter(_tokens(hyp)), Counter(_tokens(ref))\n",
    "    inter = sum((ht & rt).values())\n",
    "    prec = inter / max(1, sum(ht.values()))\n",
    "    rec = inter / max(1, sum(rt.values()))\n",
    "    f1 = 0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "    return prec, rec, f1\n",
    "\n",
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "    _rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    def rouge_metrics(hyp, ref):\n",
    "        s = _rouge.score(ref, hyp)\n",
    "        return {\n",
    "            \"rouge1_f\": s[\"rouge1\"].fmeasure,\n",
    "            \"rouge2_f\": s[\"rouge2\"].fmeasure,\n",
    "            \"rougeL_f\": s[\"rougeL\"].fmeasure\n",
    "        }\n",
    "except Exception:\n",
    "    def rouge_metrics(hyp, ref):\n",
    "        prec, rec, f1 = prf1_unigram(hyp, ref)\n",
    "        return {\"rouge1_f\": f1, \"rouge2_f\": None, \"rougeL_f\": None}\n",
    "\n",
    "def get_topk_refs(text, retriever, k=3):\n",
    "    docs = retriever.invoke(text)[:k]\n",
    "    return [d.page_content for d in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87aaa497-2af4-4040-b2f6-8f0f6f1bc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ë¡œë“œ\n",
    "_embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-small\")\n",
    "\n",
    "def score_bot_utterance(bot_utterance, retriever, k=3):\n",
    "    \"\"\"\n",
    "    ì±—ë´‡ ë°œí™”(bot_utterance)ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ì„ ì°¾ê³ \n",
    "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ + BERTScoreë¡œ í‰ê°€ (ROUGE ì œê±°)\n",
    "    \"\"\"\n",
    "    # 1) ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (FAISS)\n",
    "    docs = retriever.invoke(bot_utterance)[:k]\n",
    "    if not docs:\n",
    "        return None\n",
    "\n",
    "    # 2) í›„ë³´ ë¬¸ì¥ í’€ ìƒì„±\n",
    "    candidates = []\n",
    "    for d in docs:\n",
    "        sents = _split_sentences(d.page_content)\n",
    "        candidates.extend(sents)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # 3) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (sentence-transformers)\n",
    "    q_emb = _embedding_model.encode(bot_utterance, normalize_embeddings=True)\n",
    "    cand_embs = _embedding_model.encode(candidates, normalize_embeddings=True)\n",
    "    sims = util.cos_sim(q_emb, cand_embs).squeeze(0).tolist()\n",
    "    best_idx = max(range(len(sims)), key=lambda i: sims[i])\n",
    "    best_sent = candidates[best_idx]\n",
    "    cosine_sim = float(sims[best_idx])\n",
    "\n",
    "    # 4) BERTScore (ko)\n",
    "    P, R, F1 = bert_score([bot_utterance], [best_sent], lang=\"ko\", rescale_with_baseline=True)\n",
    "    bert_p = float(P[0]); bert_r = float(R[0]); bert_f1 = float(F1[0])\n",
    "\n",
    "    # 5) ë°˜í™˜\n",
    "    return {\n",
    "        \"ref\": best_sent,\n",
    "        \"f1\": cosine_sim,\n",
    "        \"cosine\": cosine_sim,\n",
    "        \"bertscore\": {\"bert_p\": bert_p, \"bert_r\": bert_r, \"bert_f1\": bert_f1},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b5421e-f8ae-4525-a432-5a9c7ba17301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# LLM í”„ë¡¬í”„íŠ¸/ì²´ì¸ ì¤€ë¹„ (RAGìš© retrieved_conversations ì œê±°)\n",
    "# ========================\n",
    "def prepare_greeting_llm(api_key):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.5,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "    greeting_system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ì•„ë™ì²­ì†Œë…„ì˜ ìƒë‹´ ì±—ë´‡ì´ì•¼.\n",
    "    - ì•„ë™ì´ í¸ì•ˆí•˜ê²Œ ëŠë¼ë„ë¡ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë°˜ë§ì„ ì‚¬ìš©í•´.\n",
    "    - ëŒ€í™”ì˜ ì²« ì‹œì‘ì´ë‹ˆ ê¸´ì¥í•˜ì§€ ì•Šë„ë¡ ê°€ë³ê³  ì¹œê·¼í•˜ê²Œ ì¸ì‚¬í•´.\n",
    "    - ë„ˆì˜ ëª©í‘œëŠ” ë„¤ê°€ ì§ˆë¬¸ì„ ì§„í–‰í•˜ê¸° ì „ ì•„ë™ì—ê²Œ ì¹œê·¼íˆ ë‹¤ê°€ê°€ ì•„ë™ì´ ì§ˆë¬¸ì„ ë°›ì„ ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ ë¬¼ì–´ë³´ëŠ” ê±°ì•¼.\n",
    "    - ì ˆëŒ€! ìœ„í—˜ ì£¼ì œ(í•™ëŒ€, ìì‚´ ë“±)ì™€ ê´€ë ¨ëœ ë‚´ìš©ì€ ì–¸ê¸‰í•˜ì§€ ë§ˆ.\n",
    "    - ì¦ê±°ìš´ ëŒ€í™”ë¼ëŠ” ë§ì„ í•˜ì§€ë§ˆ.\n",
    "    - ì§„ì¤‘í•œ ëŒ€í™”ë¥¼ í•˜ê²Œë  ê±°ì•¼. ì•„ë™ì—ê² í¸í•˜ê²Œ ë§í•´ë‹¬ë¼ê³  í•´ë„ ì¢‹ì•„.\n",
    "    - ë„ˆëŠ” ì¼ë°©ì ìœ¼ë¡œ ì§ˆë¬¸ë§Œ í•˜ê²Œ ë ê±°ê³  ì•„ë™ì´ í•˜ëŠ” ì§ˆë¬¸ì€ ë°›ì§€ ì•Šì„ ê³„íšì´ë‹ˆê¹Œ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë´ë¼ëŠ” ë§ì€ í•˜ì§€ë§ˆ.\n",
    "    - ì§ˆë¬¸í•  ë•Œ í•œ ëŒ€í™”ì— ê°™ì€ ì˜ë¯¸ì˜ ë§ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•˜ì§€ë§ˆ.\n",
    "    - 1~2ë¬¸ì¥ ì •ë„ë¡œ ì§§ê²Œë§Œ ë§í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    greeting_human_prompt = \"\"\"\n",
    "    --- í˜„ì¬ ëŒ€í™” ë§¥ë½ ---\n",
    "    - ì´ë²ˆ ì„¸ì…˜ ëŒ€í™” ê¸°ë¡:\n",
    "    {conversation_history}\n",
    "    - ì•„ë™ì˜ ìµœê·¼ ë‹µë³€: {user_response}\n",
    "\n",
    "    - ìƒë‹´ ì¤€ë¹„ ì§ˆë¬¸ì„ í•´ì¤˜: {ask_ready} (True/False)\n",
    "\n",
    "    ìœ„ ëª¨ë“  ë§¥ë½ì„ ì°¸ê³ í•´ì„œ ë‹¤ìŒ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.\n",
    "    \"\"\"\n",
    "\n",
    "    greeting_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", greeting_system_prompt),\n",
    "        (\"human\", greeting_human_prompt)\n",
    "    ])\n",
    "\n",
    "    return greeting_prompt, llm\n",
    "\n",
    "def prepare_readiness_judge_llm(api_key):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "    judge_system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ì•„ë™ì²­ì†Œë…„ ìƒë‹´ì˜ ì‹œì‘ ì¤€ë¹„ ìƒíƒœë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì•¼.\n",
    "    ì£¼ì–´ì§„ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì•„ë™ì´ ì‹¬ì¸µì ì¸ ìƒë‹´ ì£¼ì œë¥¼ ì´ì–´ê°ˆ ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì¤˜.\n",
    "\n",
    "    [íŒë‹¨ ê¸°ì¤€]\n",
    "    1. ì±—ë´‡ì´ ë§ˆì§€ë§‰ìœ¼ë¡œ \"ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€\"ì— ëŒ€í•´ ë¬¼ì–´ë´¤ê³ , ì•„ë™ì´ ì´ì— ê¸ì •ì /ì ê·¹ì ìœ¼ë¡œ ì‘ë‹µí•˜ë©° ì°¸ì—¬ ì˜ì§€ë¥¼ ë³´ì˜€ëŠ”ê°€?\n",
    "    2. ë¶€ì •ì ì´ê±°ë‚˜ íšŒí”¼ì ì¸ ì‘ë‹µì´ ì£¼ë¥¼ ì´ë£¨ì§€ ì•Šì•˜ëŠ”ê°€?\n",
    "\n",
    "    [ì¶œë ¥]\n",
    "    - STOP ë˜ëŠ” KEEP í•œ ë‹¨ì–´ë§Œ ì¶œë ¥.\n",
    "    \"\"\"\n",
    "\n",
    "    judge_human_prompt = \"\"\"\n",
    "    - ìµœê·¼ê¹Œì§€ì˜ ì´ˆê¸° ëŒ€í™” ë‚´ìš©:\n",
    "    {initial_conversation_history}\n",
    "\n",
    "    ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë™ì´ ì‹¬ì¸µì ì¸ ìƒë‹´ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ ì‹ ì¤‘í•˜ê²Œ íŒë‹¨í•´ì¤˜.\n",
    "    STOP ë˜ëŠ” KEEP í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    judge_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", judge_system_prompt),\n",
    "        (\"human\", judge_human_prompt)\n",
    "    ])\n",
    "\n",
    "    return judge_prompt, llm\n",
    "\n",
    "def prepare_first_question_llm(api_key):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.9,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "    first_question_system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ì•„ë™ì²­ì†Œë…„ì˜ ìœ„í—˜ ìƒíƒœë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ì•¼. ë„ˆëŠ” ì•„ë™ê³¼ ê°™ì€ ë‚˜ì´ì˜ ë˜ë˜ì•¼.\n",
    "    - ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬(category)ì— ë§ëŠ” ì²« ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘í•´.\n",
    "    - ê°™ì€ ì£¼ì œë¼ë„ ë§¤ë²ˆ ë˜‘ê°™ì€ ì§ˆë¬¸ì„ ë°˜ë³µí•˜ì§€ ë§ˆ.\n",
    "    - ì•„ë™ì´ ê¸´ì¥í•˜ì§€ ì•Šë„ë¡ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ½ê²Œ ë°˜ë§ì„ ì‚¬ìš©í•´.\n",
    "    - ë„ˆë¬´ ê¹Šê±°ë‚˜ ìœ„í˜‘ì ì¸ ì§ˆë¬¸ì€ í”¼í•˜ê³ , ì˜¤í”ˆí˜• ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•´.\n",
    "    - ë°˜ë“œì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´.\n",
    "    - ì§€ë‚œ ë‚  ë‚˜ëˆ´ë˜ ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì„ í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    first_question_human_prompt = \"\"\"\n",
    "    - í˜„ì¬ ìƒë‹´ ì£¼ì œ: \"{category}\"\n",
    "    ìœ„ì˜ ì£¼ì œì™€ ë§¥ë½ì„ ì°¸ê³ í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì²« ì§ˆë¬¸ì„ ì‘ì„±í•´ì¤˜.\n",
    "    \"\"\"\n",
    "\n",
    "    first_question_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", first_question_system_prompt),\n",
    "        (\"human\", first_question_human_prompt)\n",
    "    ])\n",
    "\n",
    "    return first_question_prompt, llm\n",
    "\n",
    "def prepare_followup_question_llm(api_key):\n",
    "    \"\"\"\n",
    "    RAGìš© retrieved_conversations í•­ëª©ì„ í”„ë¡¬í”„íŠ¸ì—ì„œ ì œê±°í•¨.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.3,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "    question_system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ì•„ë™ì²­ì†Œë…„ì˜ ìœ„í—˜ ìƒíƒœë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ì•¼.\n",
    "    - ì•„ë™ì´ í¸ì•ˆí•˜ê²Œ ë‹µí•  ìˆ˜ ìˆë„ë¡ ë¶€ë“œëŸ¬ìš´ ë°˜ë§ì„ ì‚¬ìš©í•´.\n",
    "    - ì ˆëŒ€!!! ë‘ ê°€ì§€ ì´ìƒì˜ ì§ˆë¬¸ì„ í•œ ë²ˆì— í•˜ì§€ ë§ˆ. í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•´!!!\n",
    "    - ë§Œ 7ì„¸~12ì‚´ ì•„ë™ì—ê²Œ ë§ëŠ” ì‰¬ìš´ ë§ì„ ì‚¬ìš©í•˜ê³  ë¶€ì •ì ì¸ í‘œí˜„ì€ í”¼í•´.\n",
    "    - í˜„ì¬ ìƒë‹´ ì£¼ì œì™€ ê´€ë ¨ëœ ë§ë§Œ í•´ì•¼ í•´.\n",
    "    - ì•„ë™ì˜ ë‹µë³€ì´ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ë‹¤ë¥¸ë§ë¡œ ë„ˆê°€ ê¶ê¸ˆí•œ ì ì„ í¬í•¨í•´ì„œ í•œë²ˆ ë” ì§ˆë¬¸í•´.\n",
    "    - ê³µê°ì„ ë§ì´ í•˜ë©´ì„œ ì§ˆë¬¸í•´ë´.\n",
    "    - ì•„ë™ì˜ ê°ì •ì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•´ë´.\n",
    "    \"\"\"\n",
    "\n",
    "    question_human_prompt = \"\"\"\n",
    "    - í˜„ì¬ ìƒë‹´ ì£¼ì œ: \"{category}\"\n",
    "\n",
    "    - ì´ë²ˆ ì„¸ì…˜ ëŒ€í™” ê¸°ë¡:\n",
    "    {conversation_history}\n",
    "\n",
    "    - ì•„ë™ì˜ ìµœê·¼ ë‹µë³€: {user_response}\n",
    "\n",
    "    ìœ„ ëª¨ë“  ë§¥ë½ì„ ì°¸ê³ í•´ì„œ ì•„ë™ì—ê²Œ ì´ì–´ì§ˆ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì¤˜.\n",
    "    \"\"\"\n",
    "\n",
    "    question_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", question_system_prompt),\n",
    "        (\"human\", question_human_prompt)\n",
    "    ])\n",
    "\n",
    "    return question_prompt, llm\n",
    "\n",
    "def prepare_judge_llm(api_key):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "\n",
    "    judge_system_prompt = \"\"\"\n",
    "    ë„ˆëŠ” ì•„ë™ì²­ì†Œë…„ì˜ ìœ„í—˜ ìƒíƒœë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì•¼.\n",
    "    í˜„ì¬ ì£¼ì œë¡œ ìƒë‹´ì„ ê³„ì†í• ì§€ ë˜ëŠ” ì „í™˜í• ì§€ íŒë‹¨í•´ì„œ KEEP ë˜ëŠ” SWITCH í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    judge_human_prompt = \"\"\"\n",
    "    - í˜„ì¬ ì£¼ì œ: \"{category}\"\n",
    "    - ìµœê·¼ê¹Œì§€ì˜ ìƒë‹´ ëŒ€í™” ë‚´ìš©:\n",
    "    {conversation_history}\n",
    "\n",
    "    ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, KEEP ë˜ëŠ” SWITCH ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•´.\n",
    "    \"\"\"\n",
    "\n",
    "    judge_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", judge_system_prompt),\n",
    "        (\"human\", judge_human_prompt)\n",
    "    ])\n",
    "\n",
    "    return judge_prompt, llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8063dcbc-d1e3-499b-9c07-175376aee2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# ì „ì²´ ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "# ========================\n",
    "def init_chatbot(api_key):\n",
    "    retriever, vectorstore, embedding_model = load_vectorstore(api_key)\n",
    "    greeting_prompt, greeting_llm = prepare_greeting_llm(api_key)\n",
    "    readiness_judge_prompt, readiness_judge_llm = prepare_readiness_judge_llm(api_key)\n",
    "    first_question_prompt, first_question_llm = prepare_first_question_llm(api_key)\n",
    "    question_prompt, question_llm = prepare_followup_question_llm(api_key)\n",
    "    judge_prompt, judge_llm = prepare_judge_llm(api_key)\n",
    "\n",
    "    greeting_chain = greeting_prompt | greeting_llm | StrOutputParser()\n",
    "    readiness_judge_chain = readiness_judge_prompt | readiness_judge_llm | StrOutputParser()\n",
    "    first_question_chain = first_question_prompt | first_question_llm | StrOutputParser()\n",
    "    question_chain = question_prompt | question_llm | StrOutputParser()\n",
    "    judge_chain = judge_prompt | judge_llm | StrOutputParser()\n",
    "\n",
    "    return {\n",
    "        \"retriever\": retriever,\n",
    "        \"vectorstore\": vectorstore,\n",
    "        \"embedding_model\": embedding_model,\n",
    "        \"greeting_chain\": greeting_chain,\n",
    "        \"readiness_judge_chain\": readiness_judge_chain,\n",
    "        \"first_question_chain\": first_question_chain,\n",
    "        \"question_chain\": question_chain,\n",
    "        \"judge_chain\": judge_chain,\n",
    "    }\n",
    "\n",
    "# ========================\n",
    "# ì²´ì¸ ë˜í¼ í•¨ìˆ˜ (RAG ê´€ë ¨ ì¸ì ì œê±°)\n",
    "# ========================\n",
    "def ask_greeting(conversation_history, user_response, ask_ready):\n",
    "    return chatbot[\"greeting_chain\"].invoke({\n",
    "        \"conversation_history\": conversation_history,\n",
    "        \"user_response\": user_response,\n",
    "        \"ask_ready\": ask_ready\n",
    "    })\n",
    "\n",
    "def judge_readiness(initial_conversation_history):\n",
    "    return chatbot[\"readiness_judge_chain\"].invoke({\n",
    "        \"initial_conversation_history\": initial_conversation_history\n",
    "    }).strip()\n",
    "\n",
    "def ask_first_question(category):\n",
    "    return chatbot[\"first_question_chain\"].invoke({\"category\": category})\n",
    "\n",
    "# ask_followup_question: ë” ì´ìƒ retrieverì—ì„œ êº¼ë‚¸ í…ìŠ¤íŠ¸ë¥¼ LLMì— ì£¼ì…í•˜ì§€ ì•ŠìŒ.\n",
    "def ask_followup_question(category, conversation_history, user_response):\n",
    "    return chatbot[\"question_chain\"].invoke({\n",
    "        \"category\": category,\n",
    "        \"conversation_history\": conversation_history,\n",
    "        \"user_response\": user_response\n",
    "    })\n",
    "\n",
    "def should_switch_topic(category, conversation_history):\n",
    "    return chatbot[\"judge_chain\"].invoke({\n",
    "        \"category\": category,\n",
    "        \"conversation_history\": conversation_history\n",
    "    }).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731e4324-1722-48b6-8818-6d81c3c3e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_sentences(text: str):\n",
    "    try:\n",
    "        import kss\n",
    "        return list(kss.split_sentences(text))\n",
    "    except Exception:\n",
    "        pattern = r'.+?(?:ë‹¤\\.|ìš”\\.|[.!?])(?:\\s+|$)'\n",
    "        sents = re.findall(pattern, text.replace('\\r', '\\n'), flags=re.DOTALL)\n",
    "        return [s.strip() for s in sents if s and s.strip()]\n",
    "\n",
    "def _strip_speaker_prefix(s):\n",
    "    return re.sub(r\"^(ìƒë‹´ì‚¬|ìƒë‹´ì|ìƒë‹´ì›|ì•„ë™|ì•„ì´|child|counselor)\\s*[:ï¼š]\\s*\", \"\", s, flags=re.IGNORECASE).strip()\n",
    "\n",
    "def _best_sentence_against(hyp, sentences):\n",
    "    best = None\n",
    "    best_score = -1.0\n",
    "    for s in sentences:\n",
    "        s_clean = _strip_speaker_prefix(s)\n",
    "        _, _, f1 = prf1_unigram(hyp, s_clean)\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best = s_clean\n",
    "    return best, best_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92756143-b6bb-46c4-b7e5-fefb5e6a126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# ì±—ë´‡ ëŒ€í™” ë£¨í”„ + (ì˜ë¯¸ê¸°ë°˜) ìœ ì‚¬ë„ í‰ê°€ ì¶œë ¥/ì €ì¥\n",
    "# ========================\n",
    "def run_conversation(category_list, max_turns=5):\n",
    "    full_conversation = []\n",
    "    retriever = chatbot[\"retriever\"]\n",
    "\n",
    "    if category_list:\n",
    "        initial_conversation_history = \"[ì‹œì‘]\\n\"\n",
    "\n",
    "        initial_question = ask_greeting(\"\", \"\", False)\n",
    "        initial_question = initial_question.replace(\"\\n\", \" \").strip()\n",
    "        print(f\"ğŸ¤– ì±—ë´‡: {initial_question}\")\n",
    "        initial_conversation_history += f\"ìƒë‹´ì‚¬: {initial_question}\\n\"\n",
    "\n",
    "        # === ìœ ì‚¬ë„ í‰ê°€ (ì²« ì¸ì‚¬)\n",
    "        metrics = score_bot_utterance(initial_question, retriever)\n",
    "        if metrics:\n",
    "            print(\"   â†³ ìœ ì‚¬ë¬¸:\", metrics['ref'][:100])\n",
    "            cos = metrics.get(\"cosine\", metrics.get(\"f1\", 0.0))\n",
    "            print(\"   â†³ Cosine:\", round(cos, 3))\n",
    "            bs = metrics.get(\"bertscore\")\n",
    "            if isinstance(bs, dict) and \"bert_f1\" in bs:\n",
    "                print(f\"   â†³ BERTScore(F1): {bs['bert_f1']:.3f} (P:{bs['bert_p']:.3f}, R:{bs['bert_r']:.3f})\")\n",
    "\n",
    "        user_response_greeting = input(\"ğŸ§’ ì•„ë™: \")\n",
    "        initial_conversation_history += f\"ì•„ë™: {user_response_greeting}\\n\"\n",
    "\n",
    "        ready_question = ask_greeting(initial_conversation_history.strip(), user_response_greeting, True)\n",
    "        ready_question = ready_question.replace(\"\\n\", \" \").strip()\n",
    "        print(f\"ğŸ¤– ì±—ë´‡: {ready_question}\")\n",
    "        initial_conversation_history += f\"ìƒë‹´ì‚¬: {ready_question}\\n\"\n",
    "\n",
    "        # === ìœ ì‚¬ë„ í‰ê°€ (ì¤€ë¹„ ì§ˆë¬¸)\n",
    "        metrics = score_bot_utterance(ready_question, retriever)\n",
    "        if metrics:\n",
    "            print(\"   â†³ ìœ ì‚¬ë¬¸:\", metrics['ref'][:100])\n",
    "            cos = metrics.get(\"cosine\", metrics.get(\"f1\", 0.0))\n",
    "            print(\"   â†³ Cosine:\", round(cos, 3))\n",
    "            bs = metrics.get(\"bertscore\")\n",
    "            if isinstance(bs, dict) and \"bert_f1\" in bs:\n",
    "                print(f\"   â†³ BERTScore(F1): {bs['bert_f1']:.3f} (P:{bs['bert_p']:.3f}, R:{bs['bert_r']:.3f})\")\n",
    "\n",
    "        user_response_ready = input(\"ğŸ§’ ì•„ë™: \")\n",
    "        initial_conversation_history += f\"ì•„ë™: {user_response_ready}\\n\"\n",
    "\n",
    "        readiness_judge = judge_readiness(initial_conversation_history)\n",
    "        print(\"DEBUG: initial_conversation_history:\\n\", initial_conversation_history)\n",
    "        print(\"DEBUG: raw readiness_judge:\", repr(readiness_judge))\n",
    "        \n",
    "        if readiness_judge == \"STOP\":\n",
    "            final_message = \"ì•Œì•˜ì–´~~ ì˜¤ëŠ˜ì€ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ê³  ì‹¶ì§€ ì•Šêµ¬ë‚˜. ê´œì°®ì•„! ë‹¤ìŒì— ì´ì•¼ê¸°í•˜ê³  ì‹¶ì„ ë•Œ ì–¸ì œë“ ì§€ ë‹¤ì‹œ ì°¾ì•„ì™€ì¤˜. í¸ì•ˆí•œ í•˜ë£¨ ë³´ë‚´ê¸¸ ë°”ë„ê²Œ!\"\n",
    "            print(f\"\\nğŸ¤– ì±—ë´‡: {final_message}\")\n",
    "            initial_conversation_history += f\"ìƒë‹´ì‚¬: {final_message}\\n\"\n",
    "            full_conversation.append(initial_conversation_history)\n",
    "            return full_conversation\n",
    "\n",
    "        full_conversation.append(initial_conversation_history)\n",
    "\n",
    "    # === ì£¼ì œë³„ ìƒë‹´\n",
    "    for category in category_list:\n",
    "        print(f\"\\n=== ìƒë‹´ ì£¼ì œ: [{category}] ===\")\n",
    "        full_conversation.append(f\"[{category}]\\n\")\n",
    "        conversation_history = \"\"\n",
    "        turn_count = 0\n",
    "\n",
    "        current_question = ask_first_question(category)\n",
    "        current_question = current_question.replace(\"\\n\", \" \").strip()\n",
    "        print(f\"ğŸ¤– ì±—ë´‡: {current_question}\")\n",
    "        conversation_history += f\"ìƒë‹´ì‚¬: {current_question}\\n\"\n",
    "\n",
    "        while turn_count < max_turns:\n",
    "            user_response = input(\"ğŸ§’ ì•„ë™: \")\n",
    "            conversation_history += f\"ì•„ë™: {user_response}\\n\"\n",
    "\n",
    "            if user_response.strip() == \"ì¢…ë£Œ\":\n",
    "                full_conversation.append(conversation_history)\n",
    "                break\n",
    "\n",
    "            judge = should_switch_topic(category, conversation_history)\n",
    "            if judge == \"SWITCH\":\n",
    "                break\n",
    "\n",
    "            current_question = ask_followup_question(category, conversation_history, user_response)\n",
    "            current_question = current_question.replace(\"\\n\", \" \").strip()\n",
    "            print(f\"ğŸ¤– ì±—ë´‡: {current_question}\")\n",
    "            conversation_history += f\"ìƒë‹´ì‚¬: {current_question}\\n\"\n",
    "\n",
    "            # === ìœ ì‚¬ë„ í‰ê°€ (í›„ì† ì§ˆë¬¸)\n",
    "            metrics = score_bot_utterance(current_question, retriever)\n",
    "            if metrics:\n",
    "                print(\"   â†³ ìœ ì‚¬ë¬¸:\", metrics['ref'][:100])\n",
    "                cos = metrics.get(\"cosine\", metrics.get(\"f1\", 0.0))\n",
    "                print(\"   â†³ Cosine:\", round(cos, 3))\n",
    "                bs = metrics.get(\"bertscore\")\n",
    "                if isinstance(bs, dict) and \"bert_f1\" in bs:\n",
    "                    print(f\"   â†³ BERTScore(F1): {bs['bert_f1']:.3f} (P:{bs['bert_p']:.3f}, R:{bs['bert_r']:.3f})\")\n",
    "\n",
    "                # âœ… ìœ ì‚¬ë¬¸ + ì ìˆ˜ CSV ì €ì¥ (ì½”ì‚¬ì¸, BERTScore ê¸°ì¤€)\n",
    "                try:\n",
    "                    with open(save_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                        bert_f1 = bs[\"bert_f1\"] if isinstance(bs, dict) else \"\"\n",
    "                        safe_ref = metrics[\"ref\"].replace(\"\\n\", \" \").replace(\",\", \"ï¼Œ\")\n",
    "                        safe_q = current_question.replace(\"\\n\", \" \").replace(\",\", \"ï¼Œ\")\n",
    "                        f.write(f\"{category},{safe_q},{safe_ref},{cos},{bert_f1}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   â†³ (CSV ì €ì¥ ì˜¤ë¥˜) {e}\")\n",
    "\n",
    "            turn_count += 1\n",
    "\n",
    "        full_conversation.append(conversation_history)\n",
    "\n",
    "    print(\"ğŸ¤– ì±—ë´‡: ì˜¤ëŠ˜ ì—¬ëŸ¬ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ì¤˜ì„œ ì •ë§ ê³ ë§ˆì›Œ! í¸ì•ˆí•œ í•˜ë£¨ ë³´ë‚´ê¸¸ ë°”ë„ê²Œ!\")\n",
    "    return full_conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f27d7543-bd13-4c03-93aa-ca75eac909c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ì €ì¥ ê²½ë¡œ ì„¤ì • ===\n",
    "import os\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "now = datetime.now(KST).strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "os.makedirs(\"result_deepchat_no_rag\", exist_ok=True)\n",
    "save_path = f\"result_deepchat_no_rag/conversation_deep_{now}.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61445a47-b176-4879-b483-f566d14d3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_PAT = re.compile(r'(ìƒë‹´ì‚¬:|ì•„ë™:)')\n",
    "\n",
    "def _parse_turns(text: str):\n",
    "    \"\"\"í•œ ë¸”ë¡ì˜ ëŒ€ì‚¬ë¥¼ {role, utterance} ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    s = text.replace('\\r', '\\n').strip()\n",
    "\n",
    "    # 'ìƒë‹´ì‚¬:' / 'ì•„ë™:' ì•ì— ì¤„ë°”ê¿ˆì„ ë„£ì–´ ì•ˆì „í•˜ê²Œ ë¼ì¸ ë¶„ë¦¬\n",
    "    s = re.sub(r'\\s*(ìƒë‹´ì‚¬:|ì•„ë™:)', r'\\n\\1', s)\n",
    "    lines = [ln.strip() for ln in s.split('\\n') if ln.strip()]\n",
    "\n",
    "    conv = []\n",
    "    for ln in lines:\n",
    "        if ln.startswith('ìƒë‹´ì‚¬:'):\n",
    "            utt = ln[len('ìƒë‹´ì‚¬:'):].strip()\n",
    "            if utt:\n",
    "                conv.append({\"role\": \"bot\", \"utterance\": utt})\n",
    "        elif ln.startswith('ì•„ë™:'):\n",
    "            utt = ln[len('ì•„ë™:'):].strip()\n",
    "            if utt:\n",
    "                conv.append({\"role\": \"user\", \"utterance\": utt})\n",
    "    return conv\n",
    "\n",
    "def convert_to_json(full_conversation):\n",
    "    json_conversation = []\n",
    "\n",
    "    for i in range(0, len(full_conversation), 2):\n",
    "        cat_raw = (full_conversation[i] or \"\").strip()\n",
    "        text_raw = (full_conversation[i + 1] if i + 1 < len(full_conversation) else \"\") or \"\"\n",
    "        text_raw = text_raw.strip()\n",
    "\n",
    "        # ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´ì— ëŒ€ì‚¬ê°€ ì„ì—¬ ìˆìœ¼ë©´ ë¶„ë¦¬\n",
    "        m = ROLE_PAT.search(cat_raw)\n",
    "        if m:\n",
    "            category = cat_raw[:m.start()]\n",
    "            leftover = cat_raw[m.start():]  # ì²« ëŒ€ì‚¬ë¶€í„° ëê¹Œì§€\n",
    "            # leftoverë¥¼ ë³¸ë¬¸ ì•ì— ë¶™ì—¬ì„œ í•¨ê»˜ íŒŒì‹±\n",
    "            text_raw = (leftover + (\"\\n\" + text_raw if text_raw else \"\")).strip()\n",
    "        else:\n",
    "            category = cat_raw\n",
    "\n",
    "        # ëŒ€ê´„í˜¸/ê°œí–‰ ì œê±° & íŠ¸ë¦¼\n",
    "        category = category.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        conversation = _parse_turns(text_raw)\n",
    "\n",
    "        json_conversation.append({\n",
    "            \"category\": category,\n",
    "            \"conversation\": conversation\n",
    "        })\n",
    "\n",
    "    return json_conversation\n",
    "\n",
    "# ========================\n",
    "# JSON ì €ì¥\n",
    "# ========================\n",
    "def save_conversation(json_conversation, folder_name=\"result_deepchat_no_rag\"):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    filename = f\"{folder_name}/conversation_deep_{date_str}.json\"\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_conversation, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"ğŸ’¾ ëŒ€í™” ê¸°ë¡ì´ {filename} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b121e606-d838-44a2-b855-e7ece1c339ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•ˆë…•! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ? ì¤€ë¹„ê°€ ë˜ë©´ ì•Œë ¤ì¤˜.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: ì € ë§Œë‚  ë•Œ ì§„ì§œ í™˜í•˜ê²Œ ì¸ì‚¬í•´ ì¤˜ìš”.\n",
      "   â†³ Cosine: 0.911\n",
      "   â†³ BERTScore(F1): 0.718 (P:0.705, R:0.731)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì¤€ë¹„ëì–´.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì¢‹ì•„! ê·¸ëŸ¼ ì‹œì‘í•´ ë³¼ê¹Œ? í¸í•˜ê²Œ ë§í•´ì¤˜ë„ ë¼.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: ì¢‹ì•„, ì•„ë‹ˆë©´ ì‹«ì–´?\n",
      "   â†³ Cosine: 0.902\n",
      "   â†³ BERTScore(F1): 0.743 (P:0.713, R:0.775)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•Œì•˜ì–´\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: initial_conversation_history:\n",
      " [ì‹œì‘]\n",
      "ìƒë‹´ì‚¬: ì•ˆë…•! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ? ì¤€ë¹„ê°€ ë˜ë©´ ì•Œë ¤ì¤˜.\n",
      "ì•„ë™: ì¤€ë¹„ëì–´.\n",
      "ìƒë‹´ì‚¬: ì¢‹ì•„! ê·¸ëŸ¼ ì‹œì‘í•´ ë³¼ê¹Œ? í¸í•˜ê²Œ ë§í•´ì¤˜ë„ ë¼.\n",
      "ì•„ë™: ì•Œì•˜ì–´\n",
      "\n",
      "DEBUG: raw readiness_judge: 'KEEP'\n",
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ë¶„ë…¸/ì§œì¦] ===\n",
      "ğŸ¤– ì±—ë´‡: ìš”ì¦˜ ë­ ë•Œë¬¸ì— í™”ê°€ ë‚˜ê±°ë‚˜ ì§œì¦ë‚¬ë˜ ì¼ ìˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [í˜•ì œìë§¤] ===\n",
      "ğŸ¤– ì±—ë´‡: í˜•ì œë‚˜ ìë§¤ë‘ ê°™ì´ ë³´ë‚´ëŠ” ì‹œê°„ì´ ë§ì•„?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì¸;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: í˜•ì œë‚˜ ìë§¤ë‘ ê°™ì´ ìˆì„ ë•Œ ì–´ë–¤ ê¸°ë¶„ì´ ë“¤ì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ìš°ë¦¬ ì¹œêµ¬ í˜•ì œìë§¤ëŠ” ëª‡ ëª…ì´ì—ìš”?\n",
      "   â†³ Cosine: 0.899\n",
      "   â†³ BERTScore(F1): 0.702 (P:0.716, R:0.689)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì™¸ë™ì´ë¼ í˜•ì œìë§¤ ì—†ì–´\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ê±±ì •] ===\n",
      "ğŸ¤– ì±—ë´‡: ìš”ì¦˜ ë§ˆìŒì†ì— ë¬´ê±°ìš´ ê±±ì •ê±°ë¦¬ê°€ ìˆìœ¼ë©´ ë‚˜ë‘ ì´ì•¼ê¸°í•´ë³¼ë˜?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ì •ì„œí•™ëŒ€] ===\n",
      "ğŸ¤– ì±—ë´‡: ì–´ì œ ëˆ„ê°€ ë„ˆí•œí…Œ í™”ë¥¼ ë‚´ê±°ë‚˜ ê¸°ë¶„ ìƒí•˜ê²Œ í•œ ì¼ ìˆì—ˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ì‹ ì²´í•™ëŒ€] ===\n",
      "ğŸ¤– ì±—ë´‡: ìš”ì¦˜ ëª¸ì€ ê´œì°®ì•„? ì–´ë”” ì•„í”„ê±°ë‚˜ ë¶ˆí¸í•œ ë°ëŠ” ì—†ì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. í˜¹ì‹œ ìš”ì¦˜ì— ë¬´ì„­ê±°ë‚˜ ê±±ì •ë˜ëŠ” ì¼ì´ ìˆì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ìš”ì¦˜ ê±±ì •í•˜ëŠ” ê²Œ ìˆì–´?\n",
      "   â†³ Cosine: 0.922\n",
      "   â†³ BERTScore(F1): 0.706 (P:0.692, R:0.721)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. í˜¹ì‹œ ìš”ì¦˜ì— ëˆ„ê°€ ë„ˆí•œí…Œ í™”ë¥¼ ë‚´ê±°ë‚˜ ë¬´ì„­ê²Œ í•œ ì  ìˆì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: ìš”ì¦˜ì€ ì•„ì €ì”¨ë“¤ë§Œ ë³´ë©´ ë¬´ì„­ê³  í™”ë‚˜ìš”.\n",
      "   â†³ Cosine: 0.917\n",
      "   â†³ BERTScore(F1): 0.746 (P:0.734, R:0.759)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì—†ë‹¤ê³ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ì„±í•™ëŒ€] ===\n",
      "ğŸ¤– ì±—ë´‡: ì–´ë–»ê²Œ ì§€ë‚´ê³  ìˆì–´? ìš”ì¦˜ ë§ˆìŒì´ ì–´ë•Œ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. ìš”ì¦˜ ë§ˆìŒì´ ì¢€ ë³µì¡í•  ìˆ˜ë„ ìˆê² êµ¬ë‚˜. í˜¹ì‹œ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ë‚˜í•œí…Œ ë§í•´ì¤„ ìˆ˜ ìˆì–´? ë„ˆì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì‹¶ì–´.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ì–´ë–¨ ë•Œ ë§ˆìŒì´ ë³µì¡í•˜ê±°ë‚˜ í˜ë“ ê°€ìš”?\n",
      "   â†³ Cosine: 0.882\n",
      "   â†³ BERTScore(F1): 0.676 (P:0.653, R:0.701)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. ë„¤ê°€ ì¤€ë¹„ëì„ ë•Œ ì´ì•¼ê¸°í•´ì¤˜ë„ ê´œì°®ì•„. í˜¹ì‹œ ì§€ê¸ˆ ë§ˆìŒì´ ì¢€ ë¬´ê±°ìš´ ëŠë‚Œì´ ë“œë‹ˆ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ì–´ë–¨ ë•Œ ë§ˆìŒì´ ë³µì¡í•˜ê±°ë‚˜ í˜ë“¤ì–´ìš”?\n",
      "   â†³ Cosine: 0.882\n",
      "   â†³ BERTScore(F1): 0.678 (P:0.666, R:0.690)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. ì§€ê¸ˆì€ ê·¸ëƒ¥ ì¡°ìš©íˆ ìˆê³  ì‹¶ì€ ê¸°ë¶„ì¼ ìˆ˜ë„ ìˆê² ë‹¤. í˜¹ì‹œ ë‚´ê°€ ë„ì™€ì¤„ ìˆ˜ ìˆëŠ” ê²Œ ìˆì„ê¹Œ? ë„ˆì˜ ë§ˆìŒì´ ì¡°ê¸ˆì´ë¼ë„ í¸í•´ì§ˆ ìˆ˜ ìˆë„ë¡ í•˜ê³  ì‹¶ì–´.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: child: ìŒ/ ì§€ê¸ˆ í¬ê²Œ í˜ë“¤ì§€ê°€ ì•Šì•„ì„œ ì˜ ëª¨ë¥´ê² ëŠ”ë°ìš”.\n",
      "   â†³ Cosine: 0.889\n",
      "   â†³ BERTScore(F1): 0.673 (P:0.661, R:0.686)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ê±°ì ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. ë„¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ê²Œ. í˜¹ì‹œ ì§€ê¸ˆ í•˜ê³  ì‹¶ì€ ì´ì•¼ê¸°ê°€ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§í•´ì¤˜. ë„ˆì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì‹¶ì–´.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: child: ì œê°€ ë§í•˜ëŠ” ë° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ë„ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.\n",
      "   â†³ Cosine: 0.902\n",
      "   â†³ BERTScore(F1): 0.681 (P:0.670, R:0.693)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´. ì§€ê¸ˆì€ ê·¸ëƒ¥ ì¡°ìš©íˆ ìˆê³  ì‹¶ì„ ìˆ˜ë„ ìˆê² ë‹¤. í˜¹ì‹œ ì§€ê¸ˆ ë§ˆìŒì†ì— ì–´ë–¤ ê¸°ë¶„ì´ ìˆëŠ”ì§€ ìƒ‰ê¹”ë¡œ í‘œí˜„í•´ë³¼ ìˆ˜ ìˆì„ê¹Œ? ì˜ˆë¥¼ ë“¤ì–´, íŒŒë€ìƒ‰ì€ ìŠ¬í”ˆ ê¸°ë¶„ì¼ ìˆ˜ë„ ìˆê³ , ë…¸ë€ìƒ‰ì€ í–‰ë³µí•œ ê¸°ë¶„ì¼ ìˆ˜ë„ ìˆì–´. ì–´ë–¤ ìƒ‰ê¹”ì´ ë– ì˜¤ë¥´ëŠ”ì§€ ê¶ê¸ˆí•´.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ê·¸ëŸ¼, ê¸°ë¶„ì´ ë‚˜ì  ë•ŒëŠ” ì–´ë–»ê²Œ í•˜ë©´ ë§ˆìŒì´ í’€ë ¤ìš”?\n",
      "   â†³ Cosine: 0.892\n",
      "   â†³ BERTScore(F1): 0.646 (P:0.622, R:0.672)\n",
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ê°€ì •í­ë ¥] ===\n",
      "ğŸ¤– ì±—ë´‡: ì§‘ì—ì„œ ê°€ì¡±ë“¤ì´ë‘ ì§€ë‚¼ ë•Œ ê¸°ë¶„ì´ ì–´ë–¤ì§€ ê¶ê¸ˆí•´.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì˜ ì§€ë‚´\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ê·¸ë ‡êµ¬ë‚˜, ì˜ ì§€ë‚¸ë‹¤ë‹ˆ ë‹¤í–‰ì´ì•¼. í˜¹ì‹œ ì§‘ì—ì„œ ì§€ë‚´ë©´ì„œ ê±±ì •ë˜ëŠ” ì¼ì´ë‚˜ ì‹«ì€ ì¼ì´ ìƒê¸´ ì  ìˆì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: ì „ì—ëŠ” ì§‘ì£¼ì¸ì´ ë¶€ëª¨ë‹˜ ì—†ì„ ë•Œ ì™€ì„œ ë§‰ ë­ë¼ê³  í•´ì„œ ë³„ë¡œì˜€ì–´ìš”.\n",
      "   â†³ Cosine: 0.897\n",
      "   â†³ BERTScore(F1): 0.671 (P:0.656, R:0.687)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì „í˜€ ì—†ì–´\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì•Œê² ì–´, ì§‘ì—ì„œ ê±±ì •ë˜ëŠ” ì¼ì´ë‚˜ ì‹«ì€ ì¼ì´ ì—†ë‹¤ê³  í•˜ë‹ˆ ë‹¤í–‰ì´ì•¼. í˜¹ì‹œ ì§‘ì—ì„œ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ì‹œê°„ì´ë‚˜ í™œë™ì´ ë­ì•¼?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: counselor: ì§‘ì—ì„œ ë­˜ í•˜ê³  ë†€ì•„ìš”?\n",
      "   â†³ Cosine: 0.903\n",
      "   â†³ BERTScore(F1): 0.671 (P:0.650, R:0.692)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [í•™êµí­ë ¥] ===\n",
      "ğŸ¤– ì±—ë´‡: í•™êµì—ì„œ ì§€ë‚´ëŠ” ë™ì•ˆ ì¹œêµ¬ë“¤ì´ë‘ ì˜ ì§€ë‚´ê³  ìˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ìŒ, ì¹œêµ¬ë“¤ì´ë‘ ì˜ ì§€ë‚´ëŠ” ê²Œ ì‰¬ìš´ ì¼ì€ ì•„ë‹ ìˆ˜ë„ ìˆì–´. í˜¹ì‹œ í•™êµì—ì„œ í˜ë“¤ê±°ë‚˜ ì†ìƒí•œ ì¼ì´ ìˆì—ˆì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: child: í•™êµ ì¹œêµ¬ë“¤ì´ë‘ ì˜ ì§€ë‚´ìš”.\n",
      "   â†³ Cosine: 0.913\n",
      "   â†³ BERTScore(F1): 0.722 (P:0.667, R:0.788)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ìŒ, ê°€ë”ì€ ë§í•˜ê¸° ì–´ë ¤ìš´ ì¼ë„ ìˆì§€. í˜¹ì‹œ ìš”ì¦˜ í•™êµì—ì„œ ë§ˆìŒì´ ë¬´ê²ê±°ë‚˜ ê±±ì •ë˜ëŠ” ì¼ì´ ìˆì–´?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Baseline not Found for bert-base-multilingual-cased on ko at C:\\Users\\songa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bert_score\\rescale_baseline/ko/bert-base-multilingual-cased.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ ìœ ì‚¬ë¬¸: child: í•™êµ ê°€ëŠ” ê²Œ ê±±ì •ì´ ë¼ìš”.\n",
      "   â†³ Cosine: 0.902\n",
      "   â†³ BERTScore(F1): 0.701 (P:0.664, R:0.742)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ìí•´/ìì‚´] ===\n",
      "ğŸ¤– ì±—ë´‡: ìš”ì¦˜ ë§ˆìŒì— ë¬´ê±°ìš´ ì§ì´ ìˆê±°ë‚˜ ë§ˆìŒì´ í˜ë“  ì ì´ ìˆì—ˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [íŠ¸ë¼ìš°ë§ˆ] ===\n",
      "ğŸ¤– ì±—ë´‡: íŠ¸ë¼ìš°ë§ˆë¼ëŠ” ê²Œ ì°¸ ë³µì¡í•œ ê°ì •ì¸ë°, í˜¹ì‹œ ìµœê·¼ì— íŠ¹ë³„íˆ ë§ˆìŒì— ë‚¨ëŠ” ì¼ì´ ìˆì—ˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ìƒë‹´ ì£¼ì œ: [ê°€ì¶œ] ===\n",
      "ğŸ¤– ì±—ë´‡: ì§‘ì´ ì•„ë‹Œ ë‹¤ë¥¸ ê³³ì—ì„œ ì ì„ ìë³¸ ì  ìˆì–´?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ§’ ì•„ë™:  ì•„ë‹ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ì±—ë´‡: ì˜¤ëŠ˜ ì—¬ëŸ¬ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ì¤˜ì„œ ì •ë§ ê³ ë§ˆì›Œ! í¸ì•ˆí•œ í•˜ë£¨ ë³´ë‚´ê¸¸ ë°”ë„ê²Œ!\n",
      "ğŸ’¾ ëŒ€í™” ê¸°ë¡ì´ result_deepchat_no_rag/conversation_deep_2025-11-03_01-12.json ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "category_list = [\n",
    "    \"ë¶„ë…¸/ì§œì¦\", \"í˜•ì œìë§¤\",\n",
    "    \"ê±±ì •\", \"ì •ì„œí•™ëŒ€\", \"ì‹ ì²´í•™ëŒ€\", \"ì„±í•™ëŒ€\",\n",
    "    \"ê°€ì •í­ë ¥\", \"í•™êµí­ë ¥\", \"ìí•´/ìì‚´\", \"íŠ¸ë¼ìš°ë§ˆ\", \"ê°€ì¶œ\"\n",
    "]\n",
    "if __name__ == \"__main__\":\n",
    "    category_list = category_list\n",
    "\n",
    "    chatbot = init_chatbot(API_KEY)\n",
    "    full_conversation = run_conversation(category_list, max_turns=5)\n",
    "    json_conversation = convert_to_json(full_conversation)\n",
    "    save_conversation(json_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9c3e8-5254-40c8-9b70-ca6b7223e324",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
